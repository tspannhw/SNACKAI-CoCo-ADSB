#!/usr/bin/env python3
"""
Snowpipe Streaming v2 REST API Client for Raspberry Pi Thermal Sensor Data

PRODUCTION MODE - HIGH-PERFORMANCE STREAMING ONLY

This client EXCLUSIVELY uses the Snowpipe Streaming v2 REST API for high-performance
data ingestion. It does NOT use:
  - Direct INSERT statements (no Snowflake Connector)
  - Batch loading via COPY INTO
  - Stage-based ingestion
  
  
ONLY Snowpipe Streaming REST API endpoints are used:
  - /v2/streaming/hostname (discover ingest host)
  - /v2/streaming/databases/{db}/schemas/{schema}/pipes/{pipe}/channels/{channel} (open/manage channel)
  - /v2/streaming/data/databases/{db}/schemas/{schema}/pipes/{pipe}/channels/{channel}/rows (append data)
  - /v2/streaming/databases/{db}/schemas/{schema}/pipes/{pipe}:bulk-channel-status (status)

Based on Snowflake's Snowpipe Streaming v2 REST API:
https://docs.snowflake.com/user-guide/snowpipe-streaming/snowpipe-streaming-high-performance-rest-api
"""

import json
import logging
import time
import sys
import os
from datetime import datetime, timezone
from typing import Dict, Optional, List
import requests
from pathlib import Path

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Import JWT authentication module
from snowflake_jwt_auth import SnowflakeJWTAuth

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('thermal_streaming.log')
    ]
)
logger = logging.getLogger(__name__)


class SnowpipeStreamingClient:
    """
    Client for Snowpipe Streaming v2 REST API - PRODUCTION MODE
    
    This client EXCLUSIVELY uses Snowpipe Streaming v2 high-performance REST API.
    NO direct inserts, NO batch loading, ONLY streaming via REST endpoints.
    
    Handles:
    - JWT/PAT authentication
    - Channel management (open, status)
    - High-performance data streaming via NDJSON over HTTP
    """
    
    def __init__(self, config_file: str = 'snowflake_config.json'):
        """
        Initialize the streaming client.
        
        This client ONLY uses Snowpipe Streaming REST API - no direct database connections.
        """
        logger.info("=" * 70)
        logger.info("SNOWPIPE STREAMING CLIENT - PRODUCTION MODE")
        logger.info("Using ONLY Snowpipe Streaming v2 REST API")
        logger.info("NO direct inserts - HIGH-PERFORMANCE STREAMING ONLY")
        logger.info("=" * 70)
        
        self.config = self._load_config(config_file)
        self.jwt_auth = SnowflakeJWTAuth(self.config)
        
        # Streaming state
        self.control_host = None
        self.ingest_host = None
        # Use unique channel name with timestamp to avoid stale token conflicts
        base_channel = self.config.get('channel_name', 'TH_CHNL')
        import datetime
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        self.channel_name = f"{base_channel}_{timestamp}"
        self.continuation_token = None
        self.offset_token = 0
        self.scoped_token = None
        self.token_expiry = None
        
        # Statistics
        self.stats = {
            'total_rows_sent': 0,
            'total_batches': 0,
            'total_bytes_sent': 0,
            'errors': 0,
            'start_time': time.time()
        }
        
        logger.info("SnowpipeStreamingClient initialized")
        logger.info(f"Database: {self.config['database']}")
        logger.info(f"Schema: {self.config['schema']}")
        logger.info(f"Table: {self.config.get('table', self.config.get('pipe', 'N/A'))}")
        logger.info(f"Channel: {self.channel_name}")
    
    def _load_config(self, config_file: str) -> Dict:
        """Load configuration from JSON file."""
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            logger.info(f"Loaded configuration from {config_file}")
            return config
        except FileNotFoundError:
            logger.error(f"Configuration file {config_file} not found")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in configuration file: {e}")
            raise
    
    def _ensure_valid_token(self):
        """Ensure we have a valid scoped token."""
        if self.scoped_token is None or (self.token_expiry and time.time() >= self.token_expiry):
            logger.info("Obtaining new scoped token...")
            self.scoped_token = self.jwt_auth.get_scoped_token()
            # Tokens typically valid for 1 hour, refresh after 50 minutes
            self.token_expiry = time.time() + 3000
            logger.info("New scoped token obtained")
    
    def discover_ingest_host(self) -> str:
        """
        Discover the ingest host URL using the hostname endpoint.
        Step 2 in the REST API tutorial.
        Updated endpoint: /v2/streaming/hostname (not /control)
        """
        logger.info("Discovering ingest host...")
        
        # Construct hostname endpoint URL
        account = self.config['account'].lower()
        self.control_host = f"https://{account}.snowflakecomputing.com"
        
        # Updated endpoint: /v2/streaming/hostname
        url = f"{self.control_host}/v2/streaming/hostname"
        
        self._ensure_valid_token()
        
        headers = {
            'Authorization': f'Bearer {self.scoped_token}',
            'Content-Type': 'application/json'
        }
        
        try:
            # Use GET method for hostname endpoint
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            
            logger.debug(f"Response status: {response.status_code}")
            logger.debug(f"Response headers: {response.headers}")
            logger.debug(f"Response body: {response.text}")
            
            # Check if response is text (hostname) or JSON
            if response.headers.get('Content-Type', '').startswith('application/json'):
                data = response.json()
                self.ingest_host = data.get('hostname') or data.get('ingest_host')
            else:
                # Response might be plain text with just the hostname
                self.ingest_host = response.text.strip()
            
            if not self.ingest_host:
                raise ValueError("No hostname returned from endpoint")
            
            logger.info(f"Ingest host discovered: {self.ingest_host}")
            return self.ingest_host
            
        except json.JSONDecodeError as e:
            # Try to use response text directly as hostname
            logger.debug(f"Response is not JSON, using as plain text: {response.text}")
            self.ingest_host = response.text.strip()
            if self.ingest_host:
                logger.info(f"Ingest host discovered (plain text): {self.ingest_host}")
                return self.ingest_host
            else:
                logger.error(f"Empty response from hostname endpoint")
                raise ValueError("Empty response from hostname endpoint")
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to discover ingest host: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logger.error(f"Response status: {e.response.status_code}")
                logger.error(f"Response body: {e.response.text}")
            raise
    
    def open_channel(self) -> Dict:
        """
        Open a streaming channel.
        Step 3 in the REST API tutorial.
        """
        logger.info(f"Opening channel: {self.channel_name}")
        
        if not self.ingest_host:
            self.discover_ingest_host()
        
        self._ensure_valid_token()
        
        db = self.config['database']
        schema = self.config['schema']
        # Get pipe name - for Snowpipe Streaming v2, we need the PIPE not the table
        pipe = self.config.get('pipe', self.config.get('table'))
        
        # Open channel endpoint - uses PIPES not TABLES
        # https://docs.snowflake.com/en/user-guide/snowpipe-streaming/snowpipe-streaming-high-performance-error-handling
        url = (
            f"https://{self.ingest_host}/v2/streaming"
            f"/databases/{db}/schemas/{schema}/pipes/{pipe}/channels/{self.channel_name}"
        )
        
        headers = {
            'Authorization': f'Bearer {self.scoped_token}',
            'Content-Type': 'application/json'
        }
        
        # Empty payload as per official docs
        payload = {}
        
        try:
            # Use PUT method with empty body
            response = requests.put(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # Debug: Log full response
            logger.debug(f"Open channel response: {json.dumps(data, indent=2)}")
            
            # Extract tokens
            self.continuation_token = data.get('next_continuation_token')
            channel_status = data.get('channel_status', {})
            self.offset_token = channel_status.get('last_committed_offset_token')
            
            # Initialize offset token to 0 if None
            if self.offset_token is None:
                self.offset_token = 0
            
            logger.info(f"Channel opened successfully")
            logger.info(f"Continuation token: {self.continuation_token}")
            logger.info(f"Initial offset token: {self.offset_token}")
            
            if not self.continuation_token:
                logger.warning("No continuation token received! This may cause issues.")
            
            return data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to open channel: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logger.error(f"Response status: {e.response.status_code}")
                logger.error(f"Response text: {e.response.text}")
            raise
    
    def insert_rows(self, rows: List[Dict]) -> int:
        """
        Insert rows to the streaming channel (alias for append_rows).
        
        Args:
            rows: List of dictionaries representing the data rows
            
        Returns:
            Number of rows inserted
        """
        if not rows:
            logger.warning("No rows to insert")
            return 0
        
        # Call append_rows
        self.append_rows(rows)
        return len(rows)
    
    def append_rows(self, rows: List[Dict]) -> Dict:
        """
        Append rows to the streaming channel.
        Step 4 in the REST API tutorial.
        
        Args:
            rows: List of dictionaries representing the data rows
            
        Returns:
            Response dictionary from the API
        """
        if not rows:
            logger.warning("No rows to append")
            return {}
        
        logger.info(f"Appending {len(rows)} rows...")
        
        if not self.ingest_host or not self.continuation_token:
            raise RuntimeError("Channel not opened. Call open_channel() first.")
        
        self._ensure_valid_token()
        
        # Increment offset for this batch
        new_offset = self.offset_token + 1
        
        db = self.config['database']
        schema = self.config['schema']
        # Get pipe name - for Snowpipe Streaming v2, we need the PIPE not the table
        pipe = self.config.get('pipe', self.config.get('table'))
        
        # Build URL with query parameters - uses PIPES not TABLES
        url = (
            f"https://{self.ingest_host}/v2/streaming/data"
            f"/databases/{db}/schemas/{schema}/pipes/{pipe}/channels/{self.channel_name}/rows"
        )
        
        # Add query parameters
        params = {
            'continuationToken': self.continuation_token,
            'offsetToken': str(new_offset)
        }
        
        logger.debug(f"Append URL: {url}")
        logger.debug(f"Params: {params}")
        
        headers = {
            'Authorization': f'Bearer {self.scoped_token}',
            'Content-Type': 'application/x-ndjson'
        }
        
        # Convert rows to NDJSON format
        ndjson_data = '\n'.join(json.dumps(row) for row in rows)
        
        try:
            response = requests.post(
                url,
                params=params,
                headers=headers,
                data=ndjson_data.encode('utf-8'),
                timeout=30
            )
            
            # Log response details if error
            if response.status_code >= 400:
                logger.error(f"Append failed with status {response.status_code}")
                logger.error(f"Response: {response.text}")
            
            response.raise_for_status()
            
            data = response.json()
            
            # Update tokens for next append
            self.continuation_token = data.get('next_continuation_token')
            
            # Update offset token only after successful append
            self.offset_token = new_offset
            
            # Update statistics
            self.stats['total_rows_sent'] += len(rows)
            self.stats['total_batches'] += 1
            self.stats['total_bytes_sent'] += len(ndjson_data)
            
            logger.info(f"Successfully appended {len(rows)} rows")
            logger.debug(f"New offset token: {self.offset_token}")
            
            return data
            
        except requests.exceptions.RequestException as e:
            self.stats['errors'] += 1
            logger.error(f"Failed to append rows: {e}")
            if hasattr(e.response, 'text'):
                logger.error(f"Response: {e.response.text}")
            raise
    
    def get_channel_status(self) -> Dict:
        """
        Get the current status of the channel.
        Step 4.4 in the REST API tutorial - Critical for verifying data persistence.
        """
        logger.debug(f"Getting channel status: {self.channel_name}")
        
        if not self.ingest_host:
            raise RuntimeError("Ingest host not discovered. Call discover_ingest_host() first.")
        
        self._ensure_valid_token()
        
        db = self.config['database']
        schema = self.config['schema']
        # Get pipe name - for Snowpipe Streaming v2, we need the PIPE not the table
        pipe = self.config.get('pipe', self.config.get('table'))
        
        url = (
            f"https://{self.ingest_host}/v2/streaming"
            f"/databases/{db}/schemas/{schema}/pipes/{pipe}:bulk-channel-status"
        )
        
        headers = {
            'Authorization': f'Bearer {self.scoped_token}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'channel_names': [self.channel_name]
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            channel_statuses = data.get('channel_statuses', {})
            channel_status = channel_statuses.get(self.channel_name, {})
            
            committed_offset = channel_status.get('committed_offset_token', 0)
            logger.debug(f"Channel committed offset: {committed_offset}")
            
            return channel_status
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Failed to get channel status: {e}")
            if hasattr(e.response, 'text'):
                logger.error(f"Response: {e.response.text}")
            raise
    
    def wait_for_commit(self, expected_offset: int, timeout: int = 60, poll_interval: int = 2) -> bool:
        """
        Wait for data to be committed to Snowflake.
        
        Args:
            expected_offset: The offset we're waiting to be committed
            timeout: Maximum time to wait in seconds
            poll_interval: How often to poll for status in seconds
            
        Returns:
            True if committed, False if timeout
        """
        logger.info(f"Waiting for offset {expected_offset} to be committed...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            try:
                status = self.get_channel_status()
                committed_offset = status.get('committed_offset_token', 0)
                
                if committed_offset >= expected_offset:
                    logger.info(f"Data committed! Offset: {committed_offset}")
                    return True
                
                logger.debug(f"Waiting... committed={committed_offset}, expected={expected_offset}")
                time.sleep(poll_interval)
                
            except Exception as e:
                logger.warning(f"Error checking status: {e}")
                time.sleep(poll_interval)
        
        logger.warning(f"Timeout waiting for commit after {timeout}s")
        return False
    
    def close_channel(self):
        """Close the streaming channel (optional - channels auto-close after inactivity)."""
        logger.info(f"Closing channel: {self.channel_name}")
        # Note: The REST API doesn't have an explicit close endpoint
        # Channels automatically close after period of inactivity
        logger.info("Channel will auto-close after inactivity period")
    
    def print_statistics(self):
        """Print ingestion statistics."""
        elapsed_time = time.time() - self.stats['start_time']
        
        logger.info("=" * 60)
        logger.info("INGESTION STATISTICS")
        logger.info("=" * 60)
        logger.info(f"Total rows sent: {self.stats['total_rows_sent']}")
        logger.info(f"Total batches: {self.stats['total_batches']}")
        logger.info(f"Total bytes sent: {self.stats['total_bytes_sent']:,}")
        logger.info(f"Errors: {self.stats['errors']}")
        logger.info(f"Elapsed time: {elapsed_time:.2f} seconds")
        
        if self.stats['total_rows_sent'] > 0:
            rows_per_sec = self.stats['total_rows_sent'] / elapsed_time
            logger.info(f"Average throughput: {rows_per_sec:.2f} rows/sec")
        
        logger.info(f"Current offset token: {self.offset_token}")
        logger.info("=" * 60)


def main():
    """Main entry point for testing."""
    logger.info("Starting Thermal Streaming Client Test")
    
    try:
        # Initialize client
        client = SnowpipeStreamingClient('snowflake_config.json')
        
        # Discover ingest host
        client.discover_ingest_host()
        
        # Open channel
        client.open_channel()
        
        # Sample thermal data (simulating your sensor)
        import socket
        actual_hostname = socket.gethostname()
        sample_data = {
            "uuid": "thrml_lgu_20250721181107",
            "ipaddress": "192.168.1.175",
            "cputempf": 126,
            "runtime": 0,
            "host": actual_hostname,
            "hostname": actual_hostname,
            "macaddress": "e4:5f:01:7c:3f:34",
            "endtime": "1753121467.469562",
            "te": "0.0008215904235839844",
            "cpu": 6.0,
            "diskusage": "92358.2 MB",
            "memory": 10.0,
            "rowid": "20250721181107_aaa0541d-135c-4156-9ad4-5de877f84d5c",
            "systemtime": "07/21/2025 14:11:08",
            "ts": int(time.time()),
            "starttime": datetime.now(timezone.utc).strftime("%m/%d/%Y %H:%M:%S"),
            "datetimestamp": datetime.now(timezone.utc).isoformat(),
            "temperature": 27.1031,
            "humidity": 48.05,
            "co2": 988.0,
            "equivalentco2ppm": 65535.0,
            "totalvocppb": 0.0,
            "pressure": 100770.23,
            "temperatureicp": 84.0
        }
        
        # Append rows
        rows = [sample_data]
        client.append_rows(rows)
        
        # Wait for commit
        client.wait_for_commit(client.offset_token, timeout=30)
        
        # Print statistics
        client.print_statistics()
        
        logger.info("Test completed successfully!")
        
    except Exception as e:
        logger.error(f"Error in main: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()

